---
title: "HW_6"
author: "Binyam Yilma"
output: github_document
---


```{r, include = FALSE}
library(tidyverse)
library(readr)
library(readxl)
library(purrr)
library(modelr)
library(patchwork)
library(mgcv)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
 ggplot2.continous.colour = "viridis",
 ggplot2.continous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

## Problem 1
Import & Filter Data
```{r, message=F}

homicide_df = 
  read_csv("./data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1,
    ),
    victim_age = as.numeric(victim_age)
  ) %>% 
  filter(!city_state %in% c("Tulsa_AL", "Dallas_TX", "Phoenix_AZ","Kansas City_MO"))  %>% 
  filter(victim_race %in% c("Black", "White")) %>% 
  filter(victim_sex %in% c("Male", "Female")) %>%  
  select(city_state, resolution, victim_age, victim_race, victim_sex)


```

####  Fit a logistic regression in Baltimore_MD
```{r}

baltimore_logitstic = homicide_df %>% 
  filter(city_state == "Baltimore_MD") %>% 
glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial() , data = .) %>%
  broom::tidy() %>% 
  mutate(
    odds_ratio = exp(estimate),
    ci_lower =  exp(estimate - 1.96 * std.error),
    ci_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, odds_ratio, starts_with("CI")) %>% 
  knitr::kable(digits = 3)

baltimore_logitstic
```

####  Fit a logistic regression on all the cities
```{r}
models_results = homicide_df %>% 
  #mutate(victim_race = fct_relevel(victim_race, "White")) %>% #reordering to compare black victims to white victims
  nest(data = -city_state) %>% 
  mutate(
    models = map(.x = data, ~ glm(resolution ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    odds_ratio = exp(estimate),
    ci_lower =  exp(estimate - 1.96 * std.error),
    ci_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, odds_ratio, starts_with("CI"))
```


#### Plot the estimated Odds Ratios and CIs for each city
```{r, fig.width=8}
models_results %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, odds_ratio)) %>% 
  ggplot(aes(x = city_state, y = odds_ratio)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
 theme(axis.text.x = element_text(angle = 60, vjust = 1.0, hjust = 1), legend.position = "none") + 
 geom_hline(yintercept=1, linetype="dashed", color = "red", size=0.5) +
  labs(
    title = "Odds Ratio of Homicide case Resolution Status, by City",
    subtitle  = "The odds ratio of case resolution, comparing male victims to female victims, controlling for age & sex",
    y = "Odds Ratio",
    x = "City-States"
  )  
```


The estimated odds of a homicide case being resolved for male victims compared to the estimated odds of a homicide case being resolved for female victims is lowest is New York City, NY (with evidence of statistical significance), adjusting for race, age; and highest in Albuquerque New Mexico, although this is not statistical significant. The former observation means that in New York City (as well as Baton Rouge, Louisiana; Omaha, Nebraska; Chicago, Illinois, and others whose Odds Ratio & and their 95% confidence interval is below the dashed red line), if the homicide victims are males, the likelihood that that case will be resolved is lower than if they were a female victim. However, this observation doesn't hold true in Boston, MA, Tampa, Florida, Atlanta, Georgia and other city-states whose odds ration and 95% confidence interval either crosses or is above the null value of odds ratio = 1 (indicated by the dashed red line.)


## Problem 2

```{r, message=F, warning=F}

baby_df = 
  read_csv("./data/birthweight.csv") %>%
  mutate(
    babysex = ifelse(babysex == 1, "male", "female") %>% as.factor(),
    frace = 
      case_when(
        frace == 1 ~ "White",
        frace == 2 ~ "Black",
        frace == 3 ~ "Asian",
        frace == 4 ~ "Puerto Rican",
        frace == 8 ~ "Other",
        frace == 9 ~ "Unknown",
        TRUE ~ ""
      ) %>% as.factor(),
    mrace = 
      case_when(
        mrace == 1 ~ "White",
        mrace == 2 ~ "Black",
        mrace == 3 ~ "Asian",
        mrace == 4 ~ "Puerto Rican",
        mrace == 8 ~ "Other",
        TRUE ~ ""
      ) %>% as.factor(),
    mrace = fct_relevel(mrace, "Other"),
    delwt = delwt*453.592 %>% round(2),
    mheight = mheight*2.54 %>% round(2)
  )

```
Tidying steps: 

* 1 Convert `babysex` to a `factor`
* 2 Label Father's race, and convert to `factor`
* 3 Label Mother's race, and convert to `factor`
* 4 Convert Mother's weight at delivery to `grams` to keep it consistent with baby's `birthweight`
* 5 Convert Mother's height to `centimeters` to keep it consistent with baby's length at birth


Checking for missing values 
```{r}
baby_df %>% skimr::skim() %>% select(skim_variable, n_missing, complete_rate) %>% knitr::kable()
```
None of the variables contain missing values


#### Proposing an initial model for birthweight

Hypothesis driven approach to build a model: 

An infant's overall health depends on the overall health status of the mother and the mother's physical ability (without considering sociodemographic factors) play important roles in determining the baby's health, and indeed the baby's birthweight. I will treat three factors as proxies of the mother's health status and physical ability: mother's `weight`, `height`, and `age`. 

Therefore, I hypothesize that a baby's `birhtweight` can be explained by a linear relationship to a mother's `weight`, adjusting for `height` and `age`. I propose to build a linear model that attempts to describe this relationship. 

First, I will assess the linearity and normality assumption a `linear` model makes. 

**Normality Assumption**
Plot the distribution of our outcome variable - `birthweight`
```{r}
baby_df %>% 
  ggplot(aes(x = bwt)) +
  geom_histogram(binwidth = 5) + 
  labs(
    title = "Distribution of Babys' birthweight",
    y = "Count",
    x = "Birthweight (in grams)"
  )
```


The histogram of a baby birth-weight in the data follows a normal distribution as shown above. 


**Linearity Assumption**

I will next assess the linearity assumption by plotting a scatter plot between the outcome variable `birthweight` and these three continuous proposed predictors. 

```{r, message=F, warning=F, fig.width=8}
bwt_delwt = baby_df %>% 
  ggplot(aes(x = bwt, y = delwt)) + 
  geom_smooth(se = F) + 
  geom_point(alpha = 0.1) + 
    labs(
    title = "Relationship between Birthweight and Mother's Weight at Delivery ",
    y = "Weight(grams)",
    x = "Birthweight (in grams)"
  )

bwt_mheight = baby_df %>% 
  ggplot(aes(x = bwt, y = mheight)) + 
  geom_smooth(se = F) + 
  geom_point(alpha = 0.1) + 
  labs(
    title = "Relationship between Birthweight and Mother's Height at Delivery ",
    y = "Height(cms)",
    x = "Birthweight (in grams)"
  )


bwt_momage = baby_df %>% 
  ggplot(aes(x = bwt, y = momage)) + 
  geom_point(alpha = 0.1) + 
  geom_smooth(se = F) + 
    labs(
    title = "Linear relationship between Birthweight and Mother's Age",
    y = "Age (years)",
    x = "Birthweight(in grams)"
  )


bwt_delwt / bwt_mheight / bwt_momage 
```

In assessing the linearity assumption between birth-weight and both mother's `weight` and & `height`, we see that there is a slight curve around 2000-2500 grams of a baby's birth-weight. But perhaps it could be argued both relationship are mostly linear. The relationship between birth-weight and mother's age, also appears to be mostly linear, with birth-weight increasing with an increase in mother's age. Here, I will assume a linear relationship exists and will move forward to build a linear model.

#### Fitting the proposed Initial model

```{r}
lin_fit = 
  baby_df %>% 
lm(bwt ~ delwt + mheight + momage, data = .) 
```

**Model summary**
```{r}
lin_fit %>% 
  broom::glance() %>% 
  select(r.squared, adj.r.squared, sigma, statistic, p.value, df, nobs) %>% 
  knitr::kable(digits = 2)
```
It appears that the initial model, with an r.squared value of 0.1, only explains about 10% of the variation in the outcome variable: baby's `birthweight`

**Model estimates**
```{r}
lin_fit %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```


Plotting residuals vs. fitted values - of the `initial model`
```{r}
baby_df %>%  
  add_residuals(lin_fit) %>% 
  add_predictions(lin_fit) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = .2) + 
  geom_smooth(se = F) + 
  labs(
    title = "Fitted Values Vs. Residuals (Initial Model)",
    x = "Model Predicted Birthweight",
    y = "Model Residuals"
  )
```

The residuals appear to be evenly distributed for the most part, save for what appears to be a cluster at weight range 3000 - 3250 grams, and a somewhat curved trend as the predicted birthweight increases. This perhaps indicates that the linear fit model has clear shortcomings when trying describe/predict birthweight, given the predictors the model is based off of. 


#### Building two additional models with different predictors & compare to the initial model: 

Two models: 

* One using length at birth and gestational age as predictors (main effects only)
* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
#model 2 - Main_Model 
baby_df %>% 
lm(bwt ~ blength + gaweeks, data = .) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

#model 3 - Interact_Model
baby_df %>% 
  lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = .) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

```



1st: Create cross validation datasets, by splitting the original sample into 80% for training and 20% for testing, and creating 100 `resample` object. 
```{r, warning=F, message=F}
cv_df = 
  crossv_mc(baby_df, 100)

#Convert the resample objects into a tibble
cv_df = cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble) 
    ) 
```


Fit the 3 models to be compared on the training datasets and compute the RMSE values of the corresponding models
```{r}
cv_df = cv_df %>% 
  mutate(
    initial_model = map(.x = train, ~lm(bwt ~ delwt + mheight + momage, data = .x)),
    main_model = map(.x = train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    interact_model = map(.x = train, ~ lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = .x))
  ) %>% 
  mutate(
    rmse_initial_model = map2_dbl(.x = initial_model, .y = test, ~rmse(model = .x, data =.y)),
    rmse_main_model = map2_dbl(.x = main_model, .y = test, ~rmse(model = .x, data =.y)),
    rmse_interact_model = map2_dbl(.x = interact_model, .y = test, ~rmse(model = .x, data =.y))
  ) 
```

Compare RMSE's of the 3 models
```{r, message=F, fig.width=8}
#tidy the cross_validation dataframe first
rmse_df = cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix =  "rmse_"
  ) 

#Outputs the mean RMSE values in a table
rmse_df %>% 
  group_by(model) %>% 
  summarize(
    mean_rmse = mean(rmse)
  ) %>% 
  knitr::kable()

#Plot the distribution of the RMSE values
rmse_df %>% 
  ggplot(aes(x = model, y =rmse, fill = model)) + 
  geom_violin(alpha = .5) + 
  geom_boxplot(alpha = .9) +
  labs(
    title = "Comparing RMSEs of the 3 models",
    y = "Root Mean Squred Error",
    x = "Models"
  )
```

Of the 3 models built here the `interact_model` (`bwt ~ bhead + blength + babysex + bhead*blength*babysex`) appears to be the best model to predict `birthweight`, using RMSE as a discriminator. 


Fit the best model
```{r}
best_model =
  baby_df %>% 
  lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = .)

best_model %>%
  broom::tidy() %>% 
  knitr::kable()
```


Plotting residuals vs. fitted values - of the 
```{r, message=F, warning=F}
baby_df %>%  
  add_residuals(best_model) %>% 
  add_predictions(best_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = .2) + 
  geom_smooth(se = F) + 
  labs(
    title = "Fitted Values Vs. Residuals (Interact_Model)",
    x = "Model Predicted Birthweight",
    y = "Model Residuals"
  )
```

The residuals appear to mostly evenly distributed in the plot shown above. 

## Problem 3

Import + Tidy 
```{r, message=F, warning=F}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```

Bootstrapping 5000 times
```{r}
bootstrap_df = weather_df %>% 
  bootstrap(5000, id = "strap_number") %>% 
  mutate(
    strap = map(strap, as_tibble), 
    models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
    results_estimates = map(models, broom::tidy),
    results_summary = map(models, broom::glance)
  ) 
```


#### Distribution of r.squared

First extract r.squared
```{r, message=F, warning=F}
r_squred_distb = bootstrap_df %>% 
  select(strap_number, results_summary) %>% 
  unnest(results_summary) %>% 
  select(r.squared) 
```

The 95% confidence interval for the estimated r-squared of the linear regression model `tmax ~ tmin`. 
```{r}
r_squred_distb %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975)  
  ) %>% 
  knitr::kable(digits = 4)
```


Plotting the distribution of the `r.squared` values obtained after bootstrapping

```{r}
r_squred_distb %>% 
  ggplot(aes(x = r.squared)) + 
   geom_density() + 
  labs(
    title = "Distribution of R squared",
    x = "R Squared",
    y = "Count"
  ) 
```

The R squared values we obtained from the `bootstrap` technique appears to be normally distributed around the mean of: `r r_squred_distb %>% pull(r.squared) %>% mean()`, with a 95% Confidence Interval of (0.894, 0.93).


#### Distribution of log(beta_0∗beta_1)
```{r, message=F, warning=F}
parameter_distb = bootstrap_df %>% 
  select(strap_number, results_estimates) %>% 
  unnest(results_estimates) %>% 
  select(term, estimate) %>% 
  mutate(
    term = 
      case_when(
        term == "(Intercept)" ~ "Intercept",
        TRUE ~ term 
      )
  ) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate,
    values_fn = list
  ) %>% 
  unnest() %>% 
  janitor::clean_names() %>% 
  mutate(
    log_b0_b1 = log(intercept*tmin)
  ) 
```

The 95% confidence interval for the log of the product of the estimated slope and intercept: log(beta_0∗beta_tmin)

```{r}
parameter_distb %>% 
  summarize(
    ci_lower = quantile(log_b0_b1, 0.025), 
    ci_upper = quantile(log_b0_b1, 0.975)  
  ) %>% 
  knitr::kable(digits = 4)
```

Plotting the distribution of the `log(beta_0∗beta_tmin)` values obtained after bootstrapping

```{r}
parameter_distb %>% 
  ggplot(aes(x = log_b0_b1)) + 
  geom_density() +
  labs(
    title = "Distribution of Log(beta_0*beta_tmin)",
    x = "Log(Beta_0*Beta_tmin)",
    y = "Count"
  ) 
```

The Log(beta_0*beta_tmin) values i.e., the distribution of the log of the product of the estimated intercept and estimated coefficient we obtained from the `bootstrap` technique also appear to be normally distributed. The mean value of `Log(beta_0 x beta_tmin)` is `r parameter_distb %>% pull(log_b0_b1) %>% mean() %>% round(2)`, with a 95% Confidence Interval of (`1.97`, `2.06`).



